{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03f2161",
   "metadata": {},
   "source": [
    "<h1> Mercado Libre Scrapping </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fa735",
   "metadata": {},
   "source": [
    "<h3> Librerias y requerimientos. </h3>\n",
    "\n",
    "- Instalación de selenium y beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d46b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e8d9",
   "metadata": {},
   "source": [
    "- Instalación de driver para uso de selenium en Google Chrome.\n",
    "\n",
    "1. Ingresar a: https://sites.google.com/chromium.org/driver/\n",
    "2. Ingresar a Downloads.\n",
    "3. Seleccionar la versión del driver de acuerdo a la versión de Google Chrome y el sistema operativo donde será instalado.\n",
    "4. Descomprimir el archivo descargado y abrir el archivo ejecutable.\n",
    "5. Extraer el path o ruta donde se encuenta el archivo chromedriver.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b266f",
   "metadata": {},
   "source": [
    "- Importar librerias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ae2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import date\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8447b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = date.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552ada2",
   "metadata": {},
   "source": [
    "<h3> 2. Mercado Libre </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e55c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ¿Qué desea buscar?: toyota hilux\n"
     ]
    }
   ],
   "source": [
    "#Definir el path del chromedriver.exe\n",
    "ChromePath = \"C:\\chromedriver.exe\"\n",
    "\n",
    "#Busqueda\n",
    "search = input(\"- ¿Qué desea buscar?: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82808cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web Driver Object\n",
    "driver = webdriver.Chrome(executable_path=ChromePath)\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.mercadolibre.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6704f39d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Seleccione el país donde realizará la busqueda: \n",
      "\n",
      "0. Argentina.\n",
      "1. Bolivia.\n",
      "2. Brasil.\n",
      "3. Chile.\n",
      "4. Colombia.\n",
      "5. Costa Rica.\n",
      "6. Dominicana.\n",
      "7. Ecuador.\n",
      "8. Guatemala.\n",
      "9. Honduras.\n",
      "10. México.\n",
      "11. Nicaragua.\n",
      "12. Panamá.\n",
      "13. Paraguay.\n",
      "14. Perú.\n",
      "15. El Salvador.\n",
      "16. Uruguay.\n",
      "17. Venezuela.\n",
      "\n",
      "Opción: 0\n",
      "\n",
      "- Usted ha seleccionado: Argentina\n"
     ]
    }
   ],
   "source": [
    "paises = BeautifulSoup(driver.page_source, 'lxml').find_all('a', {'class': 'ml-site-link'}) #Convertir página a xml\n",
    "lista_paises = pd.DataFrame(paises).reset_index().rename(columns={0:'Pais','index':'Option'})\n",
    "\n",
    "print(\"- Seleccione el país donde realizará la busqueda: \\n\")\n",
    "for i in range(len(lista_paises)):\n",
    "    print(f\"{i}. {lista_paises.loc[i,'Pais']}.\")\n",
    "\n",
    "option = int(input(\"\\nOpción: \"))\n",
    "selection = lista_paises.loc[option,'Pais']\n",
    "print(f\"\\n- Usted ha seleccionado: {selection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42539f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Hay 42 páginas disponibles. ¿Cuantás desea consultar?: 10\n"
     ]
    }
   ],
   "source": [
    "for i in paises:\n",
    "    if selection in i:\n",
    "        i = str(i)\n",
    "        url = i.split('href=\"')[1].split('\" id')[0] #Extraer URL del listado\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#Insertar busqueda\n",
    "driver.find_element_by_class_name('nav-search-input').send_keys(search)\n",
    "driver.find_element_by_class_name('nav-search-input').send_keys(Keys.RETURN)\n",
    "\n",
    "#Paginación\n",
    "time.sleep(2)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "paginas = BeautifulSoup(driver.page_source, 'html').find('li',{'class':'andes-pagination__page-count'}).get_text().replace(\"de \",\"\")\n",
    "paginas = BeautifulSoup(driver.page_source, 'html').find('li',{'class':'andes-pagination__page-count'}).get_text().replace(\"de \",\"\")\n",
    "pags = int(input(f\"\\n- Hay {paginas} páginas disponibles. ¿Cuantás desea consultar?: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5037a958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Página 1 cargada.\n",
      "- Página 2 cargada.\n",
      "- Página 3 cargada.\n",
      "- Página 4 cargada.\n",
      "- Página 5 cargada.\n",
      "- Página 6 cargada.\n",
      "- Página 7 cargada.\n",
      "- Página 8 cargada.\n",
      "- Página 9 cargada.\n",
      "- Página 10 cargada.\n"
     ]
    }
   ],
   "source": [
    "#Scrapping\n",
    "df = pd.DataFrame(columns = [\"Articulo\",\"Año\",\"Kilometraje\",\"Und Monet\",\"Precio\",\"URL\",\"Foto\"]) #Estructura DataFrame final\n",
    "pag = 1\n",
    "for pag in range(1, pags+1):\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    #Página actual\n",
    "    current_page = BeautifulSoup(driver.page_source, 'html').find('span',{'class':'andes-pagination__link'}).get_text()\n",
    "    soup = BeautifulSoup(driver.page_source, 'html').find('section', {'class': 'ui-search-results'}) #Convertir página a xml\n",
    "    soup = soup.find_all('li','ui-search-layout__item')\n",
    "    \n",
    "    for i in soup:\n",
    "        #print(i.find('title'))\n",
    "        #print(i.find(\"h1\").get_text().strip())\n",
    "        url = i.find('a')['href']\n",
    "        articulo = i.find('a')['title']\n",
    "        photo = i.find('div',{'class':'slick-slide slick-active'}).find('img')['src']\n",
    "        und = i.find('span',{'class':'price-tag-amount'}).find('span',{'class':'price-tag-symbol'}).get_text().strip()\n",
    "        price = i.find('span',{'class':'price-tag-amount'}).find('span',{'class':'price-tag-fraction'}).get_text().strip()\n",
    "        attributes = i.find_all('li',{'class':'ui-search-card-attributes__attribute'})\n",
    "        if len(attributes) > 1:\n",
    "            aux = []\n",
    "            for j in attributes:\n",
    "                aux.append(j.get_text())\n",
    "\n",
    "            year = aux[0]\n",
    "            km = aux[1]\n",
    "\n",
    "        row = pd.Series([articulo,year,km,und,price,url,photo], index = df.columns)\n",
    "\n",
    "        #Población de DataFrame con datos de cada perfil\n",
    "        df = df.append(row, ignore_index=True)\n",
    "    \n",
    "    print(f\"- Página {current_page} cargada.\")\n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_xpath(\"//li[@class='andes-pagination__button andes-pagination__button--next']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9fbaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Se exportaron 480 artículos.\n"
     ]
    }
   ],
   "source": [
    "#Exportar Datos\n",
    "df.to_excel(f\"{fecha} Mercado Libre {selection} - {search} .xlsx\")\n",
    "print(f\"- Se exportaron {len(df)} artículos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
